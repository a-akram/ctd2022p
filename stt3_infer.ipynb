{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Inference after GNN Stage_\n",
    "\n",
    "**_Inference_** is done using callbacks defined in the **_LightningModules/GNN/Models/inference.py_**. The callbacks run during the **_test_step()_** _a.k.a_ model _**evalution**_.\n",
    "\n",
    "### How to run _Inference_?\n",
    "\n",
    "1. _`traintrack config/pipeline_quickstart.yaml`_. One can use `--inference` flag to run only the `test_step()` (Should work, but failed.)\n",
    "2. _`infer.ipynb`_ notebook runs the _pl.Trainer().test()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import trackml.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN import InteractionGNN\n",
    "from LightningModules.GNN import GNNBuilder, GNNMetrics\n",
    "from LightningModules.GNN.Models.infer import GNNTelemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['EXATRKX_DATA'] = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## _Classifier Evaluation_\n",
    "\n",
    "Metrics to evaluate the GNN networks:\n",
    "\n",
    "- Accuracy/ACC = $TP+TN/TP+TN+FP+FN$\n",
    "- sensitivity, recall, hit rate, or true positive rate ($TPR = 1 - FNR$)\n",
    "- specificity, selectivity or true negative rate ($TNR = 1 - FPR$)\n",
    "- miss rate or false negative rate ($FNR = 1 - TPR$)\n",
    "- fall-out or false positive rate ($FPR = 1 - TNR$)\n",
    "- F1-score = $2 \\times (\\text{PPV} \\times \\text{TPR})/(\\text{PPV} + \\text{TPR})$\n",
    "- Efficiency/Recall/Sensitivity/Hit Rate: $TPR = TP/(TP+FN)$\n",
    "- Purity/Precision/Positive Predictive Value: $PPV = TP/(TP+FP$\n",
    "- AUC-ROC Curve $\\equiv$ FPR ($x-$axis) v.s. TPR ($y-$axis) plot\n",
    "- AUC-PRC Curve $\\equiv$ TPR ($x-$axis) v.s. PPV ($y-$axis) plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Test Dataset_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test Dataset from GNNBuilder\n",
    "inputdir=\"run/gnn_processed/test\"\n",
    "all_events = sorted(glob.glob(os.path.join(inputdir, \"*\")))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load Single Event\n",
    "test_event = torch.load(all_events[0], map_location=device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_event"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loaded_events = []\n",
    "for event in tqdm(all_events):\n",
    "    loaded_events.append(torch.load(event, map_location=device))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PyG DataLoader\n",
    "test_dataloader = DataLoader(loaded_events, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fetch One Batch\n",
    "sampled_data = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print One Batch\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Load Checkpoint_\n",
    "\n",
    "Lightning automatically saves a checkpoint for you in your current working directory, with the state of your last training epoch. We have checkpoint stored after training is finished.\n",
    "\n",
    "```\n",
    "# load a LightningModule along with its weights & hyperparameters from a checkpoint\n",
    "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
    "print(model.input_dir)\n",
    "```\n",
    "\n",
    "Note that we have saved our hyperparameters when our **LightningModule** was initialized i.e. `self.save_hyperparameters(hparams)`\n",
    "\n",
    "```\n",
    "# hyperparameters are saved to the “hyper_parameters” key in the checkpoint, to access them\n",
    "checkpoint = torch.load(path/to/checkpoint, map_location=device)\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "```\n",
    "\n",
    "One can also initialize the model with different hyperparameters (if they are saved).\n",
    "\n",
    "\n",
    "For more details, consult [Lighting Checkpointing](https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfvKUCvjUlQA"
   },
   "source": [
    "### _Get Hyperparameter Config File_\n",
    "\n",
    "- Either from the configs folder \n",
    "- Or extract it from the checkpoint, favoured if model is trained and evaluated on two different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processing config file (trusted source)\n",
    "config = None\n",
    "config_file = os.path.join(os.curdir, 'LightningModules/GNN/configs/train_alldata_GNN.yaml')\n",
    "with open(config_file) as f:\n",
    "    try:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader) # equiv: yaml.full_load(f)\n",
    "    except yaml.YAMLError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n"
     ]
    }
   ],
   "source": [
    "# Load Model Checkpoint\n",
    "ckpnt_path = \"run_all/lightning_models/lightning_checkpoints/GNNStudy/version_1/checkpoints/last.ckpt\"\n",
    "checkpoint = torch.load(ckpnt_path, map_location=device)\n",
    "pp.pprint(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Hyperparameters\n",
    "hparams = checkpoint[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Can Modify Hyperparameters\n",
    "hparams[\"checkpoint_path\"] = ckpnt_path\n",
    "hparams[\"input_dir\"] = \"run/feature_store\"\n",
    "hparams[\"output_dir\"] = \"run/gnn_processed\"\n",
    "hparams[\"artifact_library\"] = \"lightning_models/lightning_checkpoints\"\n",
    "hparams[\"train_split\"] = [0, 0, 10000]\n",
    "hparams[\"map_location\"] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Hyperparameters\n",
    "# pp.pprint(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init InteractionGNN\n",
    "model = InteractionGNN(hparams)\n",
    "model = model.load_from_checkpoint(**hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of InteractionGNN(\n",
       "  (node_encoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (edge_encoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (edge_network): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (node_network): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (output_edge_classifier): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=128, bias=True)\n",
       "    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (8): ReLU()\n",
       "    (9): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Lightning Trainer\n",
    "# trainer = pl.Trainer(callbacks=[GNNTelemetry()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Test Loop\n",
    "# trainer.test(model=model, dataloaders=None, ckpt_path=None, verbose=True, datamodule=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Prediction_\n",
    "\n",
    "- Create a DataModule\n",
    "- Get Predict Dataloader\n",
    "- Load a Checkpoint and Predict (Alternatively use `predict_step()` in LightningModule, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from LightningModules.GNN.utils.data_utils import split_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SttDataModule(pl.LightningDataModule):\n",
    "    \"\"\"\"DataModules are a way of decoupling data-related hooks from the LightningModule\"\"\"\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters(hparams)\n",
    "        \n",
    "        # Set workers from hparams\n",
    "        self.n_workers = (\n",
    "            self.hparams[\"n_workers\"]\n",
    "            if \"n_workers\" in self.hparams\n",
    "            else len(os.sched_getaffinity(0))\n",
    "        )\n",
    "        \n",
    "        self.data_split = (\n",
    "            self.hparams[\"train_split\"]\n",
    "            if \"train_split\" in self.hparams\n",
    "            else [0,0,5000]\n",
    "        )\n",
    "        \n",
    "        self.trainset, self.valset, self.testset = None, None, None\n",
    "        self.predset = None\n",
    "        \n",
    "        \n",
    "    def print_params(self):\n",
    "        pp.pprint(self.hparams)\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.trainset, self.valset, self.testset = split_datasets(**self.hparams)\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            print(\"Number of Test Events: \", self.hparams['train_split'][2])\n",
    "            self.testset = load_dataset(self.hparams[\"input_dir\"], self.data_split[2])\n",
    "            \n",
    "        if stage == \"pred\" or stage is None:\n",
    "            print(\"Number of Pred Events: \", self.hparams['train_split'][2])\n",
    "            self.predset = load_dataset(self.hparams[\"input_dir\"], self.data_split[2])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.trainset is not None:\n",
    "            return DataLoader(\n",
    "                self.trainset, batch_size=1, num_workers=self.n_workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.valset is not None:\n",
    "            return DataLoader(\n",
    "                self.valset, batch_size=1, num_workers=self.n_workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.testset is not None:\n",
    "            return DataLoader(\n",
    "                self.testset, batch_size=1, num_workers=self.n_workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    #def predict_dataloader(self):\n",
    "    #    if self.predset is not None:\n",
    "    #        return DataLoader(\n",
    "    #            self.predset, batch_size=1, num_workers=self.n_workers\n",
    "    #        )  # , pin_memory=True, persistent_workers=True)\n",
    "    #    else:\n",
    "    #        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare LightningDataModule (Error)\n",
    "dm = SttDataModule(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test Events:  10000\n"
     ]
    }
   ],
   "source": [
    "dm.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over test_dataloader\n",
    "# for batch in dm.test_dataloader():\n",
    "#    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test_dataloader\n",
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one batch\n",
    "batch = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[170, 3], pid=[170], layers=[170], event_file=[1], hid=[170], pt=[170], modulewise_true_edges=[2, 160], layerwise_true_edges=[2, 162], edge_index=[2, 1039], y_pid=[1039], batch=[170], ptr=[2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Helper Function\n",
    "def get_input_data(batch):\n",
    "    input_data = batch.x\n",
    "    input_data[input_data != input_data] = 0\n",
    "\n",
    "    return input_data\n",
    "\n",
    "\n",
    "# 2 - Helper Function\n",
    "def handle_directed(batch, edge_sample, truth_sample, directed=False):\n",
    "\n",
    "    edge_sample = torch.cat([edge_sample, edge_sample.flip(0)], dim=-1)\n",
    "    truth_sample = truth_sample.repeat(2)\n",
    "\n",
    "    if directed:\n",
    "        direction_mask = batch.x[edge_sample[0], 0] < batch.x[edge_sample[1], 0]\n",
    "        edge_sample = edge_sample[:, direction_mask]\n",
    "        truth_sample = truth_sample[direction_mask]\n",
    "\n",
    "    return edge_sample, truth_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[170, 3], pid=[170], layers=[170], event_file=[1], hid=[170], pt=[170], modulewise_true_edges=[2, 160], layerwise_true_edges=[2, 162], edge_index=[2, 1039], y_pid=[1039], batch=[170], ptr=[2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model input\n",
    "batch = next(iter(test_dataloader))\n",
    "truth = batch.y_pid\n",
    "edge_sample, truth_sample = handle_directed(batch, batch.edge_index, truth)\n",
    "input_data = get_input_data(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_data, edge_sample).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2078])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9993e-01, 1.1721e-04, 9.6153e-05,  ..., 8.4563e-05, 8.0483e-05,\n",
       "        7.9189e-05])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.scores = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = score > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[170, 3], pid=[170], layers=[170], event_file=[1], hid=[170], pt=[170], modulewise_true_edges=[2, 160], layerwise_true_edges=[2, 162], edge_index=[2, 1039], y_pid=[1039], batch=[170], ptr=[2], scores=[2078])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _TensorBoard Logger_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard notebook extension\n",
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=run_all/lightning_models/lightning_checkpoints/GNNStudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
