{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Inference after GNN Stage_\n",
    "\n",
    "**_Inference_** is done using callbacks defined in the **_LightningModules/GNN/Models/inference.py_**. The callbacks run during the **_test_step()_** _a.k.a_ model _**evalution**_.\n",
    "\n",
    "### How to run _Inference_?\n",
    "\n",
    "1. _`traintrack config/pipeline_quickstart.yaml`_. One can use `--inference` flag to run only the `test_step()` (Should work, but failed.)\n",
    "2. _`infer.ipynb`_ notebook runs the _pl.Trainer().test()_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import trackml.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['EXATRKX_DATA'] = os.path.abspath(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN import InteractionGNN\n",
    "from LightningModules.GNN import GNNBuilder, GNNMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN.Models.infer import GNNTelemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## _Classifier Evaluation_\n",
    "\n",
    "Metrics to evaluate the GNN networks:\n",
    "\n",
    "- Accuracy/ACC = $TP+TN/TP+TN+FP+FN$\n",
    "- sensitivity, recall, hit rate, or true positive rate ($TPR = 1 - FNR$)\n",
    "- specificity, selectivity or true negative rate ($TNR = 1 - FPR$)\n",
    "- miss rate or false negative rate ($FNR = 1 - TPR$)\n",
    "- fall-out or false positive rate ($FPR = 1 - TNR$)\n",
    "- F1-score = $2 \\times (\\text{PPV} \\times \\text{TPR})/(\\text{PPV} + \\text{TPR})$\n",
    "- Efficiency/Recall/Sensitivity/Hit Rate: $TPR = TP/(TP+FN)$\n",
    "- Purity/Precision/Positive Predictive Value: $PPV = TP/(TP+FP$\n",
    "- AUC-ROC Curve $\\equiv$ FPR ($x-$axis) v.s. TPR ($y-$axis) plot\n",
    "- AUC-PRC Curve $\\equiv$ TPR ($x-$axis) v.s. PPV ($y-$axis) plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Test Dataset_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test Dataset from GNNBuilder\n",
    "inputdir=\"run/gnn_processed/test\"\n",
    "all_events = sorted(glob.glob(os.path.join(inputdir, \"*\")))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load Single Event\n",
    "test_event = torch.load(all_events[0], map_location=device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_event"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loaded_events = []\n",
    "for event in tqdm(all_events):\n",
    "    loaded_events.append(torch.load(event, map_location=device))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# PyG DataLoader\n",
    "test_dataloader = DataLoader(loaded_events, batch_size=1, num_workers=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Fetch One Batch\n",
    "sampled_data = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Print One Batch\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Load Checkpoint_\n",
    "\n",
    "Lightning automatically saves a checkpoint for you in your current working directory, with the state of your last training epoch. We have checkpoint stored after training is finished.\n",
    "\n",
    "```\n",
    "# load a LightningModule along with its weights & hyperparameters from a checkpoint\n",
    "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
    "print(model.input_dir)\n",
    "```\n",
    "\n",
    "Note that we have saved our hyperparameters when our **LightningModule** was initialized i.e. `self.save_hyperparameters(hparams)`\n",
    "\n",
    "```\n",
    "# hyperparameters are saved to the “hyper_parameters” key in the checkpoint, to access them\n",
    "checkpoint = torch.load(path/to/checkpoint, map_location=device)\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "```\n",
    "\n",
    "One can also initialize the model with different hyperparameters (if they are saved).\n",
    "\n",
    "\n",
    "For more details, consult [Lighting Checkpointing](https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfvKUCvjUlQA"
   },
   "source": [
    "### _Get Hyperparameter Config File_\n",
    "\n",
    "- Either from the configs folder \n",
    "- Or extract it from the checkpoint, favoured if model is trained and evaluated on two different machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processing config file (trusted source)\n",
    "config = None\n",
    "config_file = os.path.join(os.curdir, 'LightningModules/GNN/configs/train_alldata_GNN.yaml')\n",
    "with open(config_file) as f:\n",
    "    try:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader) # equiv: yaml.full_load(f)\n",
    "    except yaml.YAMLError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model Checkpoint\n",
    "ckpnt_path = \"run_all/lightning_models/lightning_checkpoints/GNNStudy/version_1/checkpoints/last.ckpt\"\n",
    "checkpoint = torch.load(ckpnt_path, map_location=device)\n",
    "config = checkpoint[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Hyperparameters\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Can Modify Hyperparameters\n",
    "config[\"checkpoint_path\"] = ckpnt_path\n",
    "config[\"input_dir\"] = \"run/feature_store\"\n",
    "config[\"output_dir\"] = \"run/gnn_processed\"\n",
    "config[\"artifact_library\"] = \"lightning_models/lightning_checkpoints\"\n",
    "config[\"datatype_split\"] = [0, 0, 10000]\n",
    "config[\"map_location\"] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Hyperparameters (New)\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init InteractionGNN with New Config\n",
    "model = InteractionGNN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Checkpoint with New Config\n",
    "model = model.load_from_checkpoint(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Lightning Trainer\n",
    "trainer = pl.Trainer(callbacks=[GNNBuilder()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Test Loop\n",
    "trainer.test(model=model, dataloaders=None, ckpt_path=None, verbose=True, datamodule=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Test with LightningDataModule_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.GNN.utils.data_utils import split_datasets, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SttDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set workers from hparams\n",
    "        self.n_workers = (\n",
    "            self.hparams[\"n_workers\"]\n",
    "            if \"n_workers\" in self.hparams\n",
    "            else len(os.sched_getaffinity(0))\n",
    "        )\n",
    "\n",
    "        # Instance Variables\n",
    "        self.train_split = self.hparams[\"train_split\"]\n",
    "        self.trainset, self.valset, self.testset = None, None, None\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            self.trainset, self.valset, self.testset = split_datasets(**self.hparams)\n",
    "\n",
    "        if stage == \"test\":\n",
    "            print(\"Number of Test Events: \", self.hparams[\"train_split\"][2])\n",
    "            self.testset = load_dataset(self.hparams[\"input_dir\"], self.train_split[2])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.trainset is not None:\n",
    "            return DataLoader(\n",
    "                self.trainset, batch_size=1, num_workers=self.n_workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        if self.valset is not None:\n",
    "            return DataLoader(\n",
    "                self.valset, batch_size=1, num_workers=self.n_workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        if self.testset is not None:\n",
    "            return DataLoader(\n",
    "                self.testset, batch_size=1, num_workers=self.n_workers\n",
    "            )  # , pin_memory=True, persistent_workers=True)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare LightningDataModule (Error)\n",
    "# dm = SttDataModule(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataloaders = dm.test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(model=model, dataloaders=None, ckpt_path=None, verbose=True, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _TensorBoard Logger_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=run_all/lightning_models/lightning_checkpoints/GNNStudy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
