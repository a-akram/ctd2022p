{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Building Graphs: Input Edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import seaborn as sns\n",
    "import trackml.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append parent dir\n",
    "sys.path.append('..')\n",
    "\n",
    "# local imports\n",
    "from src import Compose_Event, Draw_Compose_Event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(+) - Input Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "input_dir = '../train_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find All Input Data Files (hits.csv, cells.csv, particles.csv, truth.csv)\n",
    "all_files = os.listdir(input_dir)\n",
    "\n",
    "# Extract File Prefixes (use e.g. xxx-hits.csv)\n",
    "suffix = '-hits.csv'\n",
    "file_prefixes = sorted(os.path.join(input_dir, f.replace(suffix, ''))\n",
    "                       for f in all_files if f.endswith(suffix))\n",
    "\n",
    "print(\"Number of Files: \", len(file_prefixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_prefixes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = 95191\n",
    "event_prefix = file_prefixes[event_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an event\n",
    "hits, tubes, particles, truth = trackml.dataset.load_event(event_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.head()\n",
    "# tubes.head()\n",
    "# particles.head()\n",
    "# truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _(+) - Build Event_\n",
    "\n",
    "- functions from _event_utils.py_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = Compose_Event(event_prefix,skewed=False)\n",
    "Draw_Compose_Event(event,figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Build Graphs_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(A) - True Edges (Layerwise)_\n",
    "\n",
    "**True Graph** is the ground truth for GNN. It is built from creating edges from _`hits`_ from the same particle but in adjacent layers. \n",
    "\n",
    "For this purpose one has _`true_edges, hits = get_layerwise_edges(event)`_ function in the _`event_util.py`_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.Processing.utils.event_utils import get_layerwise_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_edges, hits = get_layerwise_edges(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(B) - Input Edges (Layerwise)_\n",
    "\n",
    "**Input Graph** is the training input to GNN. It is build from edges from hits from all particles but in adjacent layers.\n",
    "\n",
    "- use same `hits` from `get_layerwise_edges()`\n",
    "- make `get_input_graph()` function similar to `get_layerwise_edges()`\n",
    "- add to Data variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_groups.size()\n",
    "# layer_groups.groups\n",
    "# layer_groups.first()\n",
    "# layer_groups.last()\n",
    "# layer_groups.ngroups\n",
    "# layer_groups.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_segments(hits1, hits2, filtering=True):\n",
    "    \n",
    "    # TODO: Impelement filtering flag\n",
    "    # Start with all possible pairs of hits\n",
    "    keys = ['event_id', 'r', 'phi', 'isochrone', 'sector_id']\n",
    "    hit_pairs = hits1[keys].reset_index().merge(hits2[keys].reset_index(), on='event_id', suffixes=('_1', '_2'))\n",
    "    \n",
    "    if filtering:\n",
    "        dSector = (hit_pairs['sector_id_1'] - hit_pairs['sector_id_2'])\n",
    "        sector_mask = ((dSector.abs() < 2) | (dSector.abs() == 5))\n",
    "        segments = hit_pairs[['index_1', 'index_2']][sector_mask]\n",
    "    else:\n",
    "        segments = hit_pairs[['index_1', 'index_2']]\n",
    "        \n",
    "    return segments\n",
    "\n",
    "def construct_graph(hits, layer_pairs, filtering=True):\n",
    "    \"\"\"Construct one graph (e.g. from one event)\"\"\"\n",
    "\n",
    "    # Loop over layer pairs and construct segments\n",
    "    layer_groups = hits.groupby('layer_id')\n",
    "    segments = []\n",
    "    for (layer1, layer2) in layer_pairs:\n",
    "        \n",
    "        # Find and join all hit pairs\n",
    "        try:\n",
    "            hits1 = layer_groups.get_group(layer1)\n",
    "            hits2 = layer_groups.get_group(layer2)\n",
    "        # If an event has no hits on a layer, we get a KeyError.\n",
    "        # In that case we just skip to the next layer pair\n",
    "        except KeyError as e:\n",
    "            logging.info('skipping empty layer: %s' % e)\n",
    "            continue\n",
    "        \n",
    "        # Construct the segments\n",
    "        segments.append(select_segments(hits1, hits2, filtering))\n",
    "    \n",
    "    # Combine segments from all layer pairs\n",
    "    # segments = pd.concat(segments)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get unique pids with freq (~ hits).\n",
    "sel_pids, sel_pids_fr = np.unique(hits.particle_id, return_counts=True)\n",
    "print(sel_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of layers, without skewed layers its just 18\n",
    "n_layers = hits.layer_id.unique().shape[0]\n",
    "print(\"total number of layers (w/o skewed): {}\".format(n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get pairs to adjacent layers\n",
    "layers = np.arange(n_layers)\n",
    "layer_pairs = np.stack([layers[:-1], layers[1:]], axis=1)\n",
    "layer_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of indices from layer pairs.\n",
    "segments = construct_graph(hits, layer_pairs, filtering=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine segments from all layer pairs\n",
    "# segments = pd.concat(segments)\n",
    "# segments.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the first layer pair (0th element)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#    print(segments[0][[\"index_1\", \"index_2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the layer pari [0,1] from segments\n",
    "edge_index = segments[0].to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.query(\"layer==0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.query(\"layer==1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index.shape[1] == len(segments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(+) - Plotting Input Edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.drawing import detector_layout\n",
    "from src.utils_math import polar_to_cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting input_edges\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "p_ids = np.unique(event.particle_id.values)\n",
    "det = pd.read_csv(\"../src/stt.csv\")\n",
    "skw = det.query('skewed==0')\n",
    "nkw = det.query('skewed==1') # one may look for +ve/-ve polarity\n",
    "    \n",
    "# detector layout\n",
    "plt.scatter(skw.x.values, skw.y.values, s=44, facecolors='none', edgecolors='lightgreen')\n",
    "plt.scatter(nkw.x.values, nkw.y.values, s=44, facecolors='none', edgecolors='coral')\n",
    "\n",
    "# particle tracks\n",
    "for pid in sel_pids:\n",
    "    idx = hits.particle_id == pid\n",
    "    ax.scatter(hits[idx].x.values, hits[idx].y.values, label='particle_id: %d' %pid)\n",
    "    \n",
    "# input edges\n",
    "for iedge in range(edge_index.shape[1]):\n",
    "    pt1 = hits.iloc[edge_index[0][iedge]]\n",
    "    pt2 = hits.iloc[edge_index[1][iedge]]\n",
    "    ax.plot([pt1.x, pt2.x], [pt1.y, pt2.y], color='k', alpha=0.3, lw=1.5)\n",
    "\n",
    "# plotting params\n",
    "ax.set_xlabel('x [cm]', fontsize=20)\n",
    "ax.set_ylabel('y [cm]', fontsize=20)\n",
    "# ax.set_title('Event ID # %d' % event_id)\n",
    "ax.set_xlim(-41, 41)\n",
    "ax.set_ylim(-41, 41)\n",
    "ax.grid(False)\n",
    "ax.legend(fontsize=11, loc='best')\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"input_edges.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Plotting Scheme\n",
    "fig, ax = detector_layout(figsize=(10,10))\n",
    "\n",
    "# particle tracks\n",
    "for pid in sel_pids:\n",
    "    idx = hits.particle_id == pid\n",
    "    ax.scatter(hits[idx].x.values, hits[idx].y.values, label='particle_id: %d' %pid)\n",
    "    \n",
    "# input edges\n",
    "for iedge in range(edge_index.shape[1]):\n",
    "    pt1 = hits.iloc[edge_index[0][iedge]]\n",
    "    pt2 = hits.iloc[edge_index[1][iedge]]\n",
    "    ax.plot([pt1.x, pt2.x], [pt1.y, pt2.y], color='k', alpha=0.3, lw=1.5)\n",
    "\n",
    "# axis params\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"input_edges.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(+) Sector-wise Filtering_\n",
    "\n",
    "* build edges only in neighouring sectors _i.e._ `|sector_id_i - sector_id_j| < 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take first layer_pair and corresponding hits\n",
    "layer_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_groups = hits.groupby('layer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits1 = layer_groups.get_group(0)\n",
    "hits2 = layer_groups.get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['event_id', 'r', 'phi', 'isochrone', 'sector_id']\n",
    "hit_pairs = hits1[keys].reset_index().merge(hits2[keys].reset_index(), on='event_id', suffixes=('_1', '_2'))\n",
    "hit_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mask = ((hit_pairs['sector_id_1'] - hit_pairs['sector_id_2']).abs() < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_pairs[['index_1', 'index_2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_pairs[['index_1', 'index_2']][sector_mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(C) - Input Edges (Modulewise)_\n",
    "\n",
    "**Input Graph** is the training input to GNN. It is build from edges from hits from all particles but in adjacent layers.\n",
    "\n",
    "- use same `hits` from `get_modulewise_ordered_edges()`\n",
    "- make `get_input_modulewise_edges()` function similar to `get_input_edges()`\n",
    "- add to Data variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.Processing.utils.event_utils import select_hits\n",
    "from LightningModules.Processing.utils.event_utils import get_modulewise_ordered_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"selection\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select hits\n",
    "hits = select_hits(event_file=event_prefix, noise=False, skewed=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN and Null Values\n",
    "signal = hits[\n",
    "    ((~hits.particle_id.isna()) & (hits.particle_id != 0)) & (~hits.vx.isna())\n",
    "]\n",
    "signal = signal.drop_duplicates(\n",
    "    subset=[\"particle_id\", \"volume_id\", \"layer_id\", \"module_id\"]\n",
    ")\n",
    "\n",
    "# Handle Indexing (Keep order of occurrence)\n",
    "signal = signal.reset_index()\n",
    "\n",
    "# Rename 'index' column to 'unsorted_index'\n",
    "signal = signal.rename(columns={\"index\": \"unsorted_index\"}).reset_index(drop=False)\n",
    "\n",
    "# Handle Particle_id 0\n",
    "signal.loc[signal[\"particle_id\"] == 0, \"particle_id\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_groups = hits.groupby(\"particle_id\", sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_groups.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pids = signal.particle_id.unique().shape[0]\n",
    "pids = np.arange(n_pids)\n",
    "pid_pairs = np.stack([pids[:-1], pids[1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for (g1, g2) in pid_pairs:\n",
    "    hits1 = layer_groups.get_group(g2)\n",
    "    hits2 = layer_groups.get_group(g2)\n",
    "    \n",
    "    keys = ['event_id', 'r', 'phi', 'isochrone', 'sector_id']\n",
    "    hit_pairs = hits1[keys].reset_index().merge(hits2[keys].reset_index(), on='event_id', suffixes=('_1', '_2'))\n",
    "    \n",
    "    dSector = (hit_pairs['sector_id_1'] - hit_pairs['sector_id_2'])\n",
    "    sector_mask = ((dSector.abs() < 2) | (dSector.abs() == 5))\n",
    "    e = hit_pairs[['index_1', 'index_2']][sector_mask]\n",
    "        \n",
    "    edges.append(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.concat(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = edges.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Plotting Scheme\n",
    "fig, ax = detector_layout(figsize=(10,10))\n",
    "\n",
    "# particle tracks\n",
    "for pid in sel_pids:\n",
    "    idx = hits.particle_id == pid\n",
    "    ax.scatter(hits[idx].x.values, hits[idx].y.values, label='particle_id: %d' %pid)\n",
    "    \n",
    "# Plot input edges\n",
    "for i, j in edge_index.T:\n",
    "    pt1 = hits.iloc[i]\n",
    "    pt2 = hits.iloc[j]\n",
    "    ax.plot([pt1.x, pt2.x], [pt1.y, pt2.y], color='gray', linewidth=0.5)\n",
    "\n",
    "\n",
    "# axis params\n",
    "ax.legend(fontsize=12, loc='best')\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"input_edges.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
