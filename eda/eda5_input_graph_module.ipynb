{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Graph Construction_\n",
    "\n",
    "- _Heuristic Method_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, sys, yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import seaborn as sns\n",
    "import trackml.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append parent dir\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cuda gpus if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from src import SttCSVDataReader, SttTorchDataReader\n",
    "from src import detector_layout\n",
    "from src import Build_Event, Build_Event_Viz, Visualize_Edges\n",
    "from src.math_utils import polar_to_cartesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Input Data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "input_dir = '../data_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find All Input Data Files (hits.csv, cells.csv, particles.csv, truth.csv)\n",
    "all_files = os.listdir(input_dir)\n",
    "\n",
    "# Extract File Prefixes (use e.g. xxx-hits.csv)\n",
    "suffix = '-hits.csv'\n",
    "file_prefixes = sorted(os.path.join(input_dir, f.replace(suffix, ''))\n",
    "                       for f in all_files if f.endswith(suffix))\n",
    "\n",
    "print(\"Number of Files: \", len(file_prefixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_prefixes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an event\n",
    "# hits, tubes, particles, truth = trackml.dataset.load_event(file_prefixes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.head()\n",
    "# tubes.head()\n",
    "# particles.head()\n",
    "# truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### _Visualize Event_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select event\n",
    "event_id = 95191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose event is exactly the same as select_hits()\n",
    "# event = Build_Event(input_dir, event_id, noise=False, skewed=False, selection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize event\n",
    "# Build_Event_Viz(event, figsize=(10,10), fig_type=\"pdf\", save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Graph Construction: Heuristic Method_\n",
    "\n",
    "Input graphs are input to a neural network, so they contain both _`True`_ and _`False`_ edges constructed by either a _heuristic method_ or _metric learning_. For supervised learning, we need node features (_`x`_), edge index (_`edge_index`_) and corresponding groud truth (_`y`_). \n",
    "\n",
    "Here we will explore a **_Heuristic Method_** to contruct input graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LightningModules.Processing.utils.event_utils import select_hits\n",
    "from LightningModules.Processing.utils.event_utils import get_layerwise_edges\n",
    "from LightningModules.Processing.utils.event_utils import get_modulewise_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(A) - Layerwise True Edges_\n",
    "\n",
    "- layerwise true edges works for high momentum particles but fails when particle re-enter the detector\n",
    "- layerwise input edges are bit inconsistent with layerwise true edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get event prefix using event_id\n",
    "event_prefix = file_prefixes[event_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select hits\n",
    "kwargs = {\"selection\": False}\n",
    "hits = select_hits(event_file=event_prefix, noise=False, skewed=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layerwise true edges & new hits dataframe\n",
    "true_edges, hits = get_layerwise_edges(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize nodes and edges\n",
    "Visualize_Edges (hits, true_edges, figsize=(10,10), fig_type=\"pdf\", save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(B) - Layerwise Input Edges_\n",
    "\n",
    "**Input Graph** is the training input to GNN. It is build from edges from hits from all particles but in adjacent layers.\n",
    "\n",
    "- use same `hits` from `get_layerwise_edges()`\n",
    "- make `get_input_graph()` function similar to `get_layerwise_edges()`\n",
    "- add to PyG `Data` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select hits\n",
    "kwargs = {\"selection\": False}\n",
    "hits = select_hits(event_file=event_prefix, noise=False, skewed=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_segments(hits1, hits2, filtering=True):\n",
    "    \n",
    "    # TODO: Impelement filtering flag\n",
    "    # Start with all possible pairs of hits\n",
    "    keys = ['event_id', 'r', 'phi', 'isochrone', 'sector_id']\n",
    "    hit_pairs = hits1[keys].reset_index().merge(hits2[keys].reset_index(), on='event_id', suffixes=('_1', '_2'))\n",
    "    \n",
    "    if filtering:\n",
    "        dSector = (hit_pairs['sector_id_1'] - hit_pairs['sector_id_2'])\n",
    "        sector_mask = ((dSector.abs() < 2) | (dSector.abs() == 5))\n",
    "        segments = hit_pairs[['index_1', 'index_2']][sector_mask]\n",
    "    else:\n",
    "        segments = hit_pairs[['index_1', 'index_2']]\n",
    "        \n",
    "    return segments\n",
    "\n",
    "def construct_graph(hits, layer_pairs, filtering=True):\n",
    "    \"\"\"Construct one graph (e.g. from one event)\"\"\"\n",
    "\n",
    "    # Loop over layer pairs and construct segments\n",
    "    layer_groups = hits.groupby('layer_id')\n",
    "    segments = []\n",
    "    for (layer1, layer2) in layer_pairs:\n",
    "        \n",
    "        # Find and join all hit pairs\n",
    "        try:\n",
    "            hits1 = layer_groups.get_group(layer1)\n",
    "            hits2 = layer_groups.get_group(layer2)\n",
    "        # If an event has no hits on a layer, we get a KeyError.\n",
    "        # In that case we just skip to the next layer pair\n",
    "        except KeyError as e:\n",
    "            logging.info('skipping empty layer: %s' % e)\n",
    "            continue\n",
    "        \n",
    "        # Construct the segments\n",
    "        segments.append(select_segments(hits1, hits2, filtering))\n",
    "    \n",
    "    # Combine segments from all layer pairs\n",
    "    # segments = pd.concat(segments)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_groups = hits.groupby('layer_id')\n",
    "# layer_groups.size()\n",
    "# layer_groups.groups\n",
    "# layer_groups.first()\n",
    "# layer_groups.last()\n",
    "# layer_groups.ngroups\n",
    "# layer_groups.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of layers, without skewed layers its just 18\n",
    "n_layers = hits.layer_id.unique().shape[0]\n",
    "print(\"total number of layers (w/o skewed): {}\".format(n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get pairs to adjacent layers\n",
    "layers = np.arange(n_layers)\n",
    "layer_pairs = np.stack([layers[:-1], layers[1:]], axis=1)\n",
    "print(\"total number of layer pairs (w/o skewed): {}\".format(layer_pairs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of indices (DataFrame) for each layer pairs.\n",
    "segments = construct_graph(hits, layer_pairs, filtering=False)\n",
    "len(segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine segments from all layer pairs\n",
    "combined_segments = pd.concat(segments)\n",
    "combined_segments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the layer pari [0,1] from segments\n",
    "input_graph = segments[0].to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_graph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_graph[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_graph[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.query(\"layer==0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hits.query(\"layer==1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_graph.shape[1] == len(segments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(+) - Plotting Input Edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize nodes and edges\n",
    "Visualize_Edges (hits, input_graph, figsize=(10,10), fig_type=\"pdf\", save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(+) Sector-wise Filtering_\n",
    "\n",
    "* build edges only in neighouring sectors _i.e._ `|sector_id_i - sector_id_j| < 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take first layer_pair and corresponding hits\n",
    "layer_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_groups = hits.groupby('layer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits1 = layer_groups.get_group(0)\n",
    "hits2 = layer_groups.get_group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['event_id', 'r', 'phi', 'isochrone', 'sector_id']\n",
    "hit_pairs = hits1[keys].reset_index().merge(hits2[keys].reset_index(), on='event_id', suffixes=('_1', '_2'))\n",
    "hit_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mask = ((hit_pairs['sector_id_1'] - hit_pairs['sector_id_2']).abs() < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_pairs[['index_1', 'index_2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_pairs[['index_1', 'index_2']][sector_mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(C) - Modulewise True Edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select hits\n",
    "kwargs = {\"selection\": False}\n",
    "hits = select_hits(event_file=event_prefix, noise=False, skewed=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layerwise true edges & new hits dataframe\n",
    "true_edges = get_modulewise_edges(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "# true_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize nodes and edges\n",
    "Visualize_Edges (hits, true_edges, figsize=(10,10), fig_type=\"pdf\", save_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _(D) - Modulewise Input Edges_\n",
    "\n",
    "**Input Graph** is the training input to GNN. It is build from edges from hits from all particles but in adjacent layers.\n",
    "\n",
    "- use same `hits` from `get_modulewise_ordered_edges()`\n",
    "- make `get_input_modulewise_edges()` function similar to `get_input_edges()`\n",
    "- add to Data variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select hits\n",
    "kwargs = {\"selection\": False}\n",
    "hits = select_hits(event_file=event_prefix, noise=False, skewed=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN and Null Values\n",
    "signal = hits[\n",
    "    ((~hits.particle_id.isna()) & (hits.particle_id != 0)) & (~hits.vx.isna())\n",
    "]\n",
    "signal = signal.drop_duplicates(\n",
    "    subset=[\"particle_id\", \"volume_id\", \"layer_id\", \"module_id\"]\n",
    ")\n",
    "\n",
    "# Handle Indexing (Keep order of occurrence)\n",
    "signal = signal.reset_index()\n",
    "\n",
    "# Rename 'index' column to 'unsorted_index'\n",
    "signal = signal.rename(columns={\"index\": \"unsorted_index\"}).reset_index(drop=False)\n",
    "\n",
    "# Handle Particle_id 0\n",
    "signal.loc[signal[\"particle_id\"] == 0, \"particle_id\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_groups = hits.groupby(\"particle_id\", sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_groups.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pids = signal.particle_id.unique().shape[0]\n",
    "pids = np.arange(n_pids)\n",
    "pid_pairs = np.stack([pids[:-1], pids[1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_groups = hits.groupby('layer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for (g1, g2) in pid_pairs:\n",
    "    hits1 = layer_groups.get_group(g1)\n",
    "    hits2 = layer_groups.get_group(g2)\n",
    "    \n",
    "    keys = ['event_id', 'r', 'phi', 'isochrone', 'sector_id']\n",
    "    hit_pairs = hits1[keys].reset_index().merge(hits2[keys].reset_index(), on='event_id', suffixes=('_1', '_2'))\n",
    "    \n",
    "    dSector = (hit_pairs['sector_id_1'] - hit_pairs['sector_id_2'])\n",
    "    sector_mask = ((dSector.abs() < 2) | (dSector.abs() == 5))\n",
    "    e = hit_pairs[['index_1', 'index_2']][sector_mask]\n",
    "        \n",
    "    edges.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_edges = pd.concat(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_edges = input_edges.to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize nodes and edges\n",
    "# Visualize_Edges (hits, input_edges, figsize=(10,10), fig_type=\"pdf\", save_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
